<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Anthony J. Clark" />
  <title>Neural Networks</title>
  <style>
    html {
      line-height: 1.7;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 40em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin-top: 1.7em;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.7em;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1.7em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1.7em 0 1.7em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      font-style: italic;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      background-color: #f0f0f0;
      font-size: 85%;
      margin: 0;
      padding: .2em .4em;
    }
    pre {
      line-height: 1.5em;
      padding: 1em;
      background-color: #f0f0f0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin-top: 1.7em;
    }
    table {
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
    }
    th, td {
      border-bottom: 1px solid lightgray;
      padding: 1em 3em 1em 0;
    }
    header {
      margin-bottom: 6em;
      text-align: center;
    }
    nav a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <link rel="stylesheet" href="css/main.css">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Neural Networks</h1>
<p class="subtitle">A concise neural network walk-through</p>
<p class="author">Anthony J. Clark</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#sec:intro"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="#sec:ethics"><span class="toc-section-number">2</span> Ethics</a></li>
<li><a href="#sec:data"><span class="toc-section-number">3</span> Data</a></li>
<li><a href="#single-neuron"><span class="toc-section-number">4</span> Single Neuron</a></li>
<li><a href="#multi-layer-networks"><span class="toc-section-number">5</span> Multi-Layer Networks</a></li>
<li><a href="#gradient-descent"><span class="toc-section-number">6</span> Gradient Descent</a></li>
<li><a href="#optimization-techniques"><span class="toc-section-number">7</span> Optimization Techniques</a></li>
<li><a href="#overfitting-and-generalization"><span class="toc-section-number">8</span> Overfitting and Generalization</a></li>
<li><a href="#sec:cnns"><span class="toc-section-number">9</span> Convolutional Neural Networks</a></li>
<li><a href="#recurrent-neural-networks"><span class="toc-section-number">10</span> Recurrent Neural Networks</a></li>
<li><a href="#advanced-topics"><span class="toc-section-number">11</span> Advanced Topics</a></li>
</ul>
</nav>
<section id="sec:intro" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Goal: provide a concise walk-through of all fundamental neural network (including modern deep learning) techniques.</p>
<p>I will not discuss every possible analogy, angle, or topic here. Instead, I will provide links to external resources so that you can choose which topics you want to investigate more closely. I will provide minimal code examples when appropriate.</p>
<p><strong>Useful prior knowledge:</strong></p>
<ul>
<li>matrix calculus
<ul>
<li>see <a href="https://explained.ai/matrix-calculus/">The Matrix Calculus You Need For Deep Learning</a> by Terence Parr and Jeremy Howard</li>
</ul></li>
<li>programming skills
<ul>
<li>I will show examples in Python, but many languages will work</li>
</ul></li>
<li>familiarity with computing tools
<ul>
<li>using a server, cloud-based services, the command line interface (CLI)</li>
</ul></li>
</ul>
<section id="background" class="level2" data-number="1.1">
<h2 data-number="1.1"><span class="header-section-number">1.1</span> Background</h2>
<p>TODO: background</p>
<ul>
<li>AI/ML/NN</li>
<li>automatic features</li>
<li>supervised/unsupervised/rl</li>
<li>applications</li>
<li>terminology (nn, ann, mlp)</li>
<li>ethics</li>
<li>non-ml example</li>
</ul>
<p>Application areas</p>
<ul>
<li>Collaborative Filtering</li>
</ul>
</section>
</section>
<section id="sec:ethics" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Ethics</h1>
</section>
<section id="sec:data" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Data</h1>
<p>Often considered the most important aspect of deep learning,</p>
<p><span class="math display">\[
\mathcal{D} = \{X, Y\}
\]</span></p>
<p>is a dataset comprising input <em>features</em> <span class="math inline">\(X\)</span> and output <em>targets</em> <span class="math inline">\(Y\)</span>. Although <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> can come in many shapes, I am going to be opinionated here and use a specific (and consistent) convention. Let’s use <span class="math inline">\(N\)</span> to denote the size of the paired dataset. (Note, not all problems have output targets, but herein I am talking about supervised learning unless otherwise specified.)</p>
<p><span class="math inline">\(X\)</span> is a matrix (indicated by capitalization) containing all features of all input examples. A single input example <span class="math inline">\(\mathbf{x}^{(i)}\)</span> is often represented as a <em>column</em> vector (indicated by boldface).</p>
<p><span class="math display">\[
\mathbf{x}^{(i)} =
\begin{bmatrix}
x^{(i)}_{1} \\
x^{(i)}_{2} \\
\vdots \\
x^{(i)}_{n_x-1} \\
x^{(i)}_{n_x} \\
\end{bmatrix}
\]</span></p>
<p>where <span class="math inline">\(n_x\)</span> is the number of input features. We do not always put the input features into a column vector (see sec. <a href="#sec:cnns">9</a> for more information), but it is a useful convention to remember.</p>
<p>Each row in <span class="math inline">\(X\)</span> is a single input example (also referred to as an instance or sample), and when you stack all <span class="math inline">\(N\)</span> examples side-by-side, you end up with</p>
<p><span class="math display">\[
X =
\begin{bmatrix}
\mathbf{x}^{(1)T}\\
\mathbf{x}^{(2)T}\\
\vdots\\
\mathbf{x}^{(N)T}
\end{bmatrix}
=
\begin{bmatrix}
x^{(1)}_{1} &amp; x^{(1)}_{2} &amp; \cdots &amp; x^{(1)}_{n_x-1} &amp; x^{(1)}_{n_x}\\
x^{(2)}_{1} &amp; x^{(2)}_{2} &amp; \cdots &amp; x^{(2)}_{n_x-1} &amp; x^{(2)}_{n_x}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
x^{(N-1)}_{1} &amp; x^{(N-1)}_{2} &amp; \cdots &amp; x^{(N-1)}_{n_x-1} &amp; x^{(N-1)}_{n_x}\\
x^{(N)}_{1} &amp; x^{(N)}_{2} &amp; \cdots &amp; x^{(N)}_{n_x-1} &amp; x^{(N)}_{n_x}\\
\end{bmatrix}.
\]</span></p>
<p>We need to transpose each example column vector (i.e., <span class="math inline">\(\mathbf{x}^{(1)T}\)</span>) into a row vector so that the first dimension of <span class="math inline">\(X\)</span> is the number of examples <span class="math inline">\(N\)</span> and the second dimension is the number of features <span class="math inline">\(n_{n_x}\)</span>. (This is not required, but it is the convention I will use for <span class="math inline">\(X\)</span>.)</p>
<p>We say that <span class="math inline">\(\mathbf{x}^{(i)} \in \mathcal{R}^{n_x}\)</span> (each input example is <span class="math inline">\(n_x\)</span> real values) and <span class="math inline">\(X \in \mathcal{R}^{N \times n_x}\)</span> (the entire input is a <span class="math inline">\((N, n_x)\)</span> matrix).</p>
<p><span class="math inline">\(Y\)</span> contains the targets (also referred to as labels or the true/correct/expected output values).</p>
<p><span class="math display">\[
Y =
\begin{bmatrix}
\mathbf{y}^{(1)T}\\
\mathbf{y}^{(2)T}\\
\vdots\\
\mathbf{y}^{(N)T}
\end{bmatrix}
=
\begin{bmatrix}
y^{(1)}_{1} &amp; y^{(1)}_{2} &amp; \cdots &amp; y^{(1)}_{n_y-1} &amp; y^{(1)}_{n_y}\\
y^{(2)}_{1} &amp; y^{(2)}_{2} &amp; \cdots &amp; y^{(2)}_{n_y-1} &amp; y^{(2)}_{n_y}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
y^{(N-1)}_{1} &amp; y^{(N-1)}_{2} &amp; \cdots &amp; y^{(N-1)}_{n_y-1} &amp; y^{(N-1)}_{n_y}\\
y^{(N)}_{1} &amp; y^{(N)}_{2} &amp; \cdots &amp; y^{(N)}_{n_y-1} &amp; y^{(N)}_{n_y}\\
\end{bmatrix}
\]</span></p>
<p>Each <span class="math inline">\(y^{(i)} \in \mathcal{R}^{n_y}\)</span> (each target is <span class="math inline">\(n_y\)</span> real values) and <span class="math inline">\(Y \in \mathcal{R}^{N \times n_y}\)</span> (the entire input is a <span class="math inline">\((N, n_y)\)</span> matrix).</p>
<p>For example, we might <strong>predict a person’s location on Earth in latitude, longitude, and altitude by looking at the temperature, illuminance, time of day, and day of year at their location</strong>. In this example, <span class="math inline">\(n_x\)</span> and <span class="math inline">\(n_y\)</span> are <span class="math inline">\(4\)</span> (temperature, illuminance, time of day, and day of year) and <span class="math inline">\(3\)</span> (latitude, longitude, and altitude), respectively. And if we have <span class="math inline">\(N=785\)</span> example pairs, then <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are <span class="math inline">\((785, 4)\)</span> and <span class="math inline">\((785, 3)\)</span>, respectively.</p>
</section>
<section id="single-neuron" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Single Neuron</h1>
<p>When our model is a single neuron we can only produce a single output. So, <span class="math inline">\(n_y=1\)</span> for this section.</p>
<section id="notation-and-diagram" class="level2" data-number="4.1">
<h2 data-number="4.1"><span class="header-section-number">4.1</span> Notation and Diagram</h2>
<p>A diagram representing a single neuron (as we’ll see later, a neural network often refers to many of these neurons interconnected):</p>
<p><img src="img/Neuron.svg" /></p>
<p>The diagram represents the following equations:</p>
<p><span class="math display">\[\begin{align}
z^{(i)} &amp;= \sum_{k=1}^{n_x} w_k x_k^{(i)} + b\\
a^{(i)} &amp;= g(z^{(i)})
\end{align}\]</span></p>
<p>The main points of this equation:</p>
<ul>
<li><span class="math inline">\(x_k^{(i)}\)</span> are the input features for the <span class="math inline">\(i^{th}\)</span> example (e.g., temperature)</li>
<li><span class="math inline">\(z^{(i)}\)</span> is a linear combination of the input features</li>
<li><span class="math inline">\(w_k\)</span> (weights) and <span class="math inline">\(b\)</span> (bias) are the <strong>learned</strong> parameters (notice the lack of any superscript)</li>
<li><span class="math inline">\(a^{(i)}\)</span> is the output of a non-linear activation function <span class="math inline">\(g(\mathord{\cdot})\)</span> applied to <span class="math inline">\(z^{(i)}\)</span></li>
<li><span class="math inline">\(\hat y^{(i)}\)</span> is the label we often give to the output (<span class="math inline">\(a^{(i)} = \hat y^{(i)}\)</span>)</li>
</ul>
<p><strong>For this model, we want to find parameters <span class="math inline">\(w_k\)</span> and <span class="math inline">\(b\)</span> such that the neuron outputs <span class="math inline">\(\hat y^{(i)} \approx y\)</span> for any input.</strong> Before we discuss optimization we should take a moment to code up this single neuron model.</p>
</section>
<section id="code-for-computing-a-neurons-output" class="level2" data-number="4.2">
<h2 data-number="4.2"><span class="header-section-number">4.2</span> Code for Computing a Neuron’s Output</h2>
<p>This code does not containing any “learning” (i.e., optimization), but it is worth showing just how simple it is to write a single neuron from scratch. Nearly all code is used to create random input data.</p>
<div class="code-highlight">
<pre>
<span style="color:#39424e;">   1</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;">!/usr/bin/env python</span>
<span style="color:#39424e;">   2</span> 
<span style="color:#39424e;">   3</span> <span style="color:#ffa759;">from</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">math</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">import</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">exp</span>
<span style="color:#39424e;">   4</span> <span style="color:#ffa759;">from</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">random</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">import</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">uniform</span>
<span style="color:#39424e;">   5</span> 
<span style="color:#39424e;">   6</span> 
<span style="color:#39424e;">   7</span> <span style="color:#ffa759;">def</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">sigmoid</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">z</span><span style="color:#ccc9c2;">:</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">float</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">-&gt;</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">float</span><span style="color:#ccc9c2;">:</span>
<span style="color:#39424e;">   8</span> <span style="color:#ccc9c2;">    </span><span style="color:#5c6773;">&quot;&quot;&quot;</span><span style="color:#5c6773;">The sigmoid/logistic activation function.</span><span style="color:#5c6773;">&quot;&quot;&quot;</span>
<span style="color:#39424e;">   9</span> <span style="color:#ccc9c2;">    </span><span style="color:#ffa759;">return</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">/</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">+</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">exp</span><span style="color:#ccc9c2;">(</span><span style="color:#f29e74;">-</span><span style="color:#ccc9c2;">z</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  10</span> 
<span style="color:#39424e;">  11</span> 
<span style="color:#39424e;">  12</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> The number of examples in our dataset</span>
<span style="color:#39424e;">  13</span> <span style="color:#ccc9c2;">N</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">100</span>
<span style="color:#39424e;">  14</span> 
<span style="color:#39424e;">  15</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> Randomly generate some input data</span>
<span style="color:#39424e;">  16</span> <span style="color:#ccc9c2;">nx</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">4</span>
<span style="color:#39424e;">  17</span> <span style="color:#ccc9c2;">x1</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">[</span><span style="color:#ffd580;">uniform</span><span style="color:#ccc9c2;">(</span><span style="color:#f29e74;">-</span><span style="color:#ffcc66;">20</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">40</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">for</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">_</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">in</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">range</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">N</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">]</span>
<span style="color:#39424e;">  18</span> <span style="color:#ccc9c2;">x2</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">[</span><span style="color:#ffd580;">uniform</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">0</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">1e6</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">for</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">_</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">in</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">range</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">N</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">]</span>
<span style="color:#39424e;">  19</span> <span style="color:#ccc9c2;">x3</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">[</span><span style="color:#ffd580;">uniform</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">0</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">24</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">*</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">60</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">*</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">60</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">for</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">_</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">in</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">range</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">N</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">]</span>
<span style="color:#39424e;">  20</span> <span style="color:#ccc9c2;">x4</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">[</span><span style="color:#f28779;">round</span><span style="color:#ccc9c2;">(</span><span style="color:#ffd580;">uniform</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">365</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">for</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">_</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">in</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">range</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">N</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">]</span>
<span style="color:#39424e;">  21</span> 
<span style="color:#39424e;">  22</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> Generate random neuron parameters</span>
<span style="color:#39424e;">  23</span> <span style="color:#ccc9c2;">w1</span><span style="color:#ccc9c2;">, </span><span style="color:#ccc9c2;">w2</span><span style="color:#ccc9c2;">, </span><span style="color:#ccc9c2;">w3</span><span style="color:#ccc9c2;">, </span><span style="color:#ccc9c2;">w4</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">[</span><span style="color:#ffd580;">uniform</span><span style="color:#ccc9c2;">(</span><span style="color:#f29e74;">-</span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">for</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">_</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">in</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">range</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">nx</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">]</span>
<span style="color:#39424e;">  24</span> <span style="color:#ccc9c2;">b</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">uniform</span><span style="color:#ccc9c2;">(</span><span style="color:#f29e74;">-</span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  25</span> 
<span style="color:#39424e;">  26</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> Compute neuron output for each of the N examples</span>
<span style="color:#39424e;">  27</span> <span style="color:#ffa759;">for</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x1i</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x2i</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x3i</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x4i</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">in</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">zip</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">x1</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x2</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x3</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x4</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">:</span>
<span style="color:#39424e;">  28</span> <span style="color:#ccc9c2;">    </span><span style="color:#ccc9c2;">zi</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">w1</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">*</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x1i</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">+</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">w2</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">*</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x2i</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">+</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">w3</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">*</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x3i</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">+</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">w4</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">*</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x4i</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">+</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">b</span>
<span style="color:#39424e;">  29</span> <span style="color:#ccc9c2;">    </span><span style="color:#ccc9c2;">ai</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">sigmoid</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">zi</span><span style="color:#ccc9c2;">)</span>

</pre>
</div>
<p>In the example, we have random parameters and we ignore the output. But what if we want to train the neuron so that the output mimics a real function or process? The next subsection tackles this very problem.</p>
</section>
<section id="optimization-with-batch-gradient-descent" class="level2" data-number="4.3">
<h2 data-number="4.3"><span class="header-section-number">4.3</span> Optimization with Batch Gradient Descent</h2>
<p>You may have noticed that in the previous code listing I also introduced a specific activation function (aka squashing function) called <code>sigmoid</code> (aka the logistic function). In this section we’</p>
<p>Do this first</p>
<p><strong>Deeper dive:</strong> TODO: something on activation functions.</p>
</section>
<section id="input-normalization" class="level2" data-number="4.4">
<h2 data-number="4.4"><span class="header-section-number">4.4</span> Input Normalization</h2>
<p>I provided <em>reasonable</em> ranges for values in the previous code example. For example, temperature values on Earth are typically in the range <span class="math inline">\([-20, 40]\)</span> °C and illuminance in the range <span class="math inline">\([0, 1e6]\)</span> Lux.</p>
<p>An NN can work with with values in these ranges, but it makes learning easier when you first scale values into the same range, typically <span class="math inline">\([-1, 1]\)</span>. TODO: why?</p>
<div class="code-highlight">
<pre>

<span style="color:#0000ee;"></span><span style="color:#444444;"> 16 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 16 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;">nx </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">4</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 17 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 17 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;">x1 </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> [</span><span style="color:#ffd580;">uniform</span><span style="color:#ccc9c2;">(</span><span style="color:#f29e74;">-</span><span style="color:#ffcc66;">20</span><span style="color:#ccc9c2;">, </span><span style="color:#ffcc66;">40</span><span style="color:#ccc9c2;">) </span><span style="color:#ffa759;">for</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">_</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">in</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">range</span><span style="color:#ccc9c2;">(N)]</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 18 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 18 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;">x2 </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> [</span><span style="color:#ffd580;">uniform</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">0</span><span style="color:#ccc9c2;">, </span><span style="color:#ffcc66;">1e6</span><span style="color:#ccc9c2;">) </span><span style="color:#ffa759;">for</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">_</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">in</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">range</span><span style="color:#ccc9c2;">(N)]</span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 19 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#a61719;">x3 </span><span style="color:#f29e74;background-color:#a61719;">=</span><span style="color:#ccc9c2;background-color:#a61719;"> [</span><span style="font-weight:bold;color:#ffd580;background-color:#901011;">uniform</span><span style="color:#ccc9c2;background-color:#a61719;">(</span><span style="color:#ffcc66;background-color:#a61719;">0</span><span style="color:#ccc9c2;background-color:#a61719;">, </span><span style="color:#ffcc66;background-color:#a61719;">24</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#f29e74;background-color:#a61719;">*</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffcc66;background-color:#a61719;">60</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#f29e74;background-color:#a61719;">*</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffcc66;background-color:#a61719;">60</span><span style="color:#ccc9c2;background-color:#a61719;">) </span><span style="color:#ffa759;background-color:#a61719;">for</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#5ccfe6;background-color:#a61719;">_</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffa759;background-color:#a61719;">in</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#f28779;background-color:#a61719;">range</span><span style="color:#ccc9c2;background-color:#a61719;">(N)]</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 19 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#22a322;">x3 </span><span style="color:#f29e74;background-color:#22a322;">=</span><span style="color:#ccc9c2;background-color:#22a322;"> [(</span><span style="color:#ffcc66;background-color:#22a322;">0</span><span style="color:#ccc9c2;background-color:#22a322;">, </span><span style="color:#ffcc66;background-color:#22a322;">24</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#f29e74;background-color:#22a322;">*</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#ffcc66;background-color:#22a322;">60</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#f29e74;background-color:#22a322;">*</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#ffcc66;background-color:#22a322;">60</span><span style="color:#ccc9c2;background-color:#22a322;">) </span><span style="color:#ffa759;background-color:#22a322;">for</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#5ccfe6;background-color:#22a322;">_</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#ffa759;background-color:#22a322;">in</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#f28779;background-color:#22a322;">range</span><span style="color:#ccc9c2;background-color:#22a322;">(N)]</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 20 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 20 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;">x4 </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> [</span><span style="color:#f28779;">round</span><span style="color:#ccc9c2;">(</span><span style="color:#ffd580;">uniform</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">, </span><span style="color:#ffcc66;">365</span><span style="color:#ccc9c2;">)) </span><span style="color:#ffa759;">for</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">_</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">in</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">range</span><span style="color:#ccc9c2;">(N)]</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 21 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 21 </span><span style="color:#0000ee;">│</span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 22 </span><span style="color:#0000ee;">│</span><span style="color:#5c6773;background-color:#22a322;"># Randomly generate some target data</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 23 </span><span style="color:#0000ee;">│</span><span style="color:#5c6773;background-color:#22a322;"># Normally, this would be something that you measure</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 24 </span><span style="color:#0000ee;">│</span><span style="color:#5c6773;background-color:#22a322;"># or label by hand</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 25 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#22a322;">ny </span><span style="color:#f29e74;background-color:#22a322;">=</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#ffcc66;background-color:#22a322;">3</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 26 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#22a322;">y1 </span><span style="color:#f29e74;background-color:#22a322;">=</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#ffcc66;background-color:#22a322;">0</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 27 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#22a322;">y2 </span><span style="color:#f29e74;background-color:#22a322;">=</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#ffcc66;background-color:#22a322;">0</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 28 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#22a322;">y3 </span><span style="color:#f29e74;background-color:#22a322;">=</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#ffcc66;background-color:#22a322;">0</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 29 </span><span style="color:#0000ee;">│</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 22 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 30 </span><span style="color:#0000ee;">│</span><span style="color:#5c6773;"># Generate random neuron parameters</span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 23 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#a61719;">w1, w2, w3, w4 </span><span style="color:#f29e74;background-color:#a61719;">=</span><span style="color:#ccc9c2;background-color:#a61719;"> [</span><span style="font-weight:bold;color:#ffd580;background-color:#901011;">uniform</span><span style="color:#ccc9c2;background-color:#a61719;">(</span><span style="color:#f29e74;background-color:#a61719;">-</span><span style="color:#ffcc66;background-color:#a61719;">1</span><span style="color:#ccc9c2;background-color:#a61719;">, </span><span style="color:#ffcc66;background-color:#a61719;">1</span><span style="color:#ccc9c2;background-color:#a61719;">) </span><span style="color:#ffa759;background-color:#a61719;">for</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#5ccfe6;background-color:#a61719;">_</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffa759;background-color:#a61719;">in</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#f28779;background-color:#a61719;">range</span><span style="color:#ccc9c2;background-color:#a61719;">(nx)]</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 31 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#22a322;">w1, w2, w3, w4 </span><span style="color:#f29e74;background-color:#22a322;">=</span><span style="color:#ccc9c2;background-color:#22a322;"> [</span><span style="font-weight:bold;color:#ffd580;background-color:#006000;">uniformity</span><span style="color:#ccc9c2;background-color:#22a322;">(</span><span style="color:#f29e74;background-color:#22a322;">-</span><span style="color:#ffcc66;background-color:#22a322;">1</span><span style="color:#ccc9c2;background-color:#22a322;">, </span><span style="color:#ffcc66;background-color:#22a322;">1</span><span style="color:#ccc9c2;background-color:#22a322;">) </span><span style="color:#ffa759;background-color:#22a322;">for</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#5ccfe6;background-color:#22a322;">_</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#ffa759;background-color:#22a322;">in</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#f28779;background-color:#22a322;">range</span><span style="color:#ccc9c2;background-color:#22a322;">(nx)]</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 24 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 32 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;">b </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">uniform</span><span style="color:#ccc9c2;">(</span><span style="color:#f29e74;">-</span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">, </span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">)</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 25 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 33 </span><span style="color:#0000ee;">│</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 26 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 34 </span><span style="color:#0000ee;">│</span><span style="color:#5c6773;"># Compute neuron output for each of the N examples</span>

</pre>
</div>
</section>
<section id="parameter-initialization" class="level2" data-number="4.5">
<h2 data-number="4.5"><span class="header-section-number">4.5</span> Parameter Initialization</h2>
</section>
<section id="the-role-of-an-activation-function" class="level2" data-number="4.6">
<h2 data-number="4.6"><span class="header-section-number">4.6</span> The Role of an Activation Function</h2>
<ul>
<li>hidden neurons
<ul>
<li>default to relu</li>
<li>try/create others to solve/investigate specific issues</li>
</ul></li>
<li>output neurons
<ul>
<li>default to sigmoid for binary classification</li>
<li>default to softmax for multi-class classification</li>
<li>default to no activation for regression</li>
</ul></li>
</ul>
</section>
<section id="vectorization-with-pytorch" class="level2" data-number="4.7">
<h2 data-number="4.7"><span class="header-section-number">4.7</span> Vectorization with PyTorch</h2>
</section>
</section>
<section id="multi-layer-networks" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Multi-Layer Networks</h1>
<ul>
<li>mlp</li>
<li>deep networks</li>
</ul>
</section>
<section id="gradient-descent" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Gradient Descent</h1>
<section id="batch-gradient-descent" class="level2" data-number="6.1">
<h2 data-number="6.1"><span class="header-section-number">6.1</span> Batch Gradient Descent</h2>
</section>
<section id="stochastic-gradient-descent" class="level2" data-number="6.2">
<h2 data-number="6.2"><span class="header-section-number">6.2</span> Stochastic Gradient Descent</h2>
</section>
<section id="mini-batch-stochastic-gradient-descent" class="level2" data-number="6.3">
<h2 data-number="6.3"><span class="header-section-number">6.3</span> Mini-Batch Stochastic Gradient Descent</h2>
<ul>
<li>SGD</li>
<li>Mini-Batch Stochastic Gradient Descent</li>
</ul>
</section>
</section>
<section id="optimization-techniques" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Optimization Techniques</h1>
</section>
<section id="overfitting-and-generalization" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Overfitting and Generalization</h1>
</section>
<section id="sec:cnns" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Convolutional Neural Networks</h1>
</section>
<section id="recurrent-neural-networks" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Recurrent Neural Networks</h1>
<p>recursive</p>
</section>
<section id="advanced-topics" class="level1" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> Advanced Topics</h1>
<ul>
<li>Generative and Adversarial Training</li>
<li>NLP, Transformers, and Attention</li>
<li>Creating ML Applications</li>
<li>Reinforcement Learning</li>
<li>Hyperparameter Tuning</li>
<li>Hybrid Networks
<ul>
<li>complex inputs and outputs</li>
</ul></li>
<li>Alternative Machine Learning Techniques</li>
</ul>
</section>
</body>
</html>
