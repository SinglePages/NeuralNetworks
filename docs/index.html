<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Anthony J. Clark" />
  <title>Neural Networks</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <link rel="stylesheet" href="css/main.css">
  <style>
      body {
          font-family: -apple-system, BlinkMacSystemFont, "Segoe UI",
              Roboto, Oxygen-Sans, Ubuntu, Cantarell,
              "Helvetica Neue", sans-serif;
      }

      code {
          font-family: SFMono-Regular, Menlo, Monaco,
              Consolas, "Liberation Mono",
              "Courier New", monospace;
      }
  </style>
</head>
<body>
<header id="title-block-header">
<h1 class="title">Neural Networks</h1>
<p class="subtitle">A concise neural network walk-through</p>
<p class="author">Anthony J. Clark</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#sec:intro"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="#sec:ethics"><span class="toc-section-number">2</span> Ethics</a></li>
<li><a href="#sec:data"><span class="toc-section-number">3</span> Data</a></li>
<li><a href="#single-neuron"><span class="toc-section-number">4</span> Single Neuron</a></li>
<li><a href="#multi-layer-networks"><span class="toc-section-number">5</span> Multi-Layer Networks</a></li>
<li><a href="#gradient-descent"><span class="toc-section-number">6</span> Gradient Descent</a></li>
<li><a href="#optimization-techniques"><span class="toc-section-number">7</span> Optimization Techniques</a></li>
<li><a href="#overfitting-and-generalization"><span class="toc-section-number">8</span> Overfitting and Generalization</a></li>
<li><a href="#sec:cnns"><span class="toc-section-number">9</span> Convolutional Neural Networks</a></li>
<li><a href="#recurrent-neural-networks"><span class="toc-section-number">10</span> Recurrent Neural Networks</a></li>
<li><a href="#transformers"><span class="toc-section-number">11</span> Transformers</a></li>
<li><a href="#sec:hyper"><span class="toc-section-number">12</span> Advanced Topics</a></li>
<li><a href="#sec:terms">Terminology</a></li>
</ul>
</nav>
<section id="sec:intro" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Goal: provide a concise walk-through of all fundamental neural network (including modern deep learning) techniques.</p>
<p>I will not discuss every possible analogy, angle, or topic here. Instead, I will provide links to external resources so that you can choose which topics you want to investigate more closely. I will provide minimal code examples when appropriate.</p>
<p><strong>Useful prior knowledge:</strong></p>
<ul>
<li>matrix calculus (see <a href="https://explained.ai/matrix-calculus/">The Matrix Calculus You Need For Deep Learning</a> by Terence Parr and Jeremy Howard)</li>
<li>programming skills (I will show examples in Python)</li>
<li>familiarity with computing tools (primarily a command line interface (CLI))</li>
</ul>
</section>
<section id="sec:ethics" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Ethics</h1>
<p><em>Being revised</em></p>
</section>
<section id="sec:data" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Data</h1>
<p>Perhaps the most important aspect of a neural network is the dataset. Let</p>
<p><span class="math display">\[
\mathcal{D} = \{X, Y\}
\]</span></p>
<p>denote a dataset comprising input <em>features</em> <span class="math inline">\(X\)</span> and output <em>targets</em> <span class="math inline">\(Y\)</span>. Although <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> can come in many shapes, I am going to be opinionated here and use a specific (and consistent) convention. Let’s use <span class="math inline">\(N\)</span> to denote the size of the paired dataset. (Note, not all problems have output targets, but herein I am talking about supervised learning unless otherwise specified.)</p>
<p>We will frequently take a dataset and split it into examples used for training, validation, and evaluation. We’ll discuss these terms near the end of this section.</p>
<p><span class="math inline">\(X\)</span> is a matrix (indicated by capitalization) containing all features of all input examples. A single input example <span class="math inline">\(\mathbf{x}^{(i)}\)</span> is often represented as a <em>column</em> vector (indicated by boldface):</p>
<p><span class="math display">\[\mathbf{x}^{(i)} = \begin{bmatrix}
x^{(i)}_{1} \\
x^{(i)}_{2} \\
\vdots \\
x^{(i)}_{n_x} \\
\end{bmatrix}
\]</span></p>
<p>where subscripts denote the feature index, <span class="math inline">\(n_x\)</span> is the number of features, and the superscript <span class="math inline">\(i\)</span> denotes that this is the <span class="math inline">\(i^{\mathit{th}}\)</span> training example. We do not always put the input features into a column vector (see sec. <a href="#sec:cnns">9</a> for more information), but it is the standard default.</p>
<p>Each row in <span class="math inline">\(X\)</span> is a single input example (also referred to as an instance or sample), and when you stack all <span class="math inline">\(N\)</span> examples on top of each other (first transposing them into row vectors), you end up with:</p>
<p><span class="math display">\[X = \begin{bmatrix}
\rule[.5ex]{1em}{0.4pt}\mathbf{x}^{(1)T}\rule[.5ex]{1em}{0.4pt} \\
\rule[.5ex]{1em}{0.4pt}\mathbf{x}^{(2)T}\rule[.5ex]{1em}{0.4pt} \\
\vdots \\
\rule[.5ex]{1em}{0.4pt}\mathbf{x}^{(N)T}\rule[.5ex]{1em}{0.4pt} \\
\end{bmatrix}
 = \begin{bmatrix}
x^{(1)}_{1} &amp; x^{(1)}_{2} &amp; \cdots &amp; x^{(1)}_{n_x}\\
x^{(2)}_{1} &amp; x^{(2)}_{2} &amp; \cdots &amp; x^{(2)}_{n_x}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
x^{(N)}_{1} &amp; x^{(N)}_{2} &amp; \cdots &amp; x^{(N)}_{n_x}\\
\end{bmatrix}
\]</span></p>
<p>We transpose each example column vector (i.e., <span class="math inline">\(\mathbf{x}^{(i)T}\)</span>) into a row vector so that the first dimension of <span class="math inline">\(X\)</span> corresponds to the number of examples <span class="math inline">\(N\)</span> and the second dimension is the number of features <span class="math inline">\(n_x\)</span>. Compare the column vector above to each row in the matrix. (This is not required, but it is the convention I will use for <span class="math inline">\(X\)</span>.)</p>
<p>Let’s denote matrix dimensions with <span class="math inline">\((r \times c)\)</span> (the number of rows <span class="math inline">\(r\)</span> by the number of columns <span class="math inline">\(c\)</span> in the matrix). I will, in text and in code, refer to matrix dimensions as the “shape” of the matrix.</p>
<details class="question">
<summary>
<strong>Question:</strong> What is the shape of <span class="math inline">\(X\)</span>?
</summary>
<div class="answer">
<strong>Answer:</strong> We say that <span class="math inline">\(\mathbf{x}^{(i)} \in \mathcal{R}^{n_x}\)</span> (each input example is <span class="math inline">\(n_x\)</span> real values) and <span class="math inline">\(X \in \mathcal{R}^{N \times n_x}\)</span>. Therefore, the shape of <span class="math inline">\(X\)</span> is <span class="math inline">\((N \times n_x)\)</span>.
</div>
</details>
<p><span class="math inline">\(Y\)</span> contains the targets (also referred to as labels or the true/correct/actual/expected output values). Here is a single target column vector:</p>
<p><span class="math display">\[\mathbf{y}^{(i)} = \begin{bmatrix}
y^{(i)}_{1} \\
y^{(i)}_{2} \\
\vdots \\
y^{(i)}_{n_y} \\
\end{bmatrix}
\]</span></p>
<p>And here is the entire target matrix including all examples:</p>
<p><span class="math display">\[Y = \begin{bmatrix}
\rule[.5ex]{1em}{0.4pt}\mathbf{y}^{(1)T}\rule[.5ex]{1em}{0.4pt} \\
\rule[.5ex]{1em}{0.4pt}\mathbf{y}^{(2)T}\rule[.5ex]{1em}{0.4pt} \\
\vdots \\
\rule[.5ex]{1em}{0.4pt}\mathbf{y}^{(N)T}\rule[.5ex]{1em}{0.4pt} \\
\end{bmatrix}
 = \begin{bmatrix}
y^{(1)}_{1} &amp; y^{(1)}_{2} &amp; \cdots &amp; y^{(1)}_{n_y}\\
y^{(2)}_{1} &amp; y^{(2)}_{2} &amp; \cdots &amp; y^{(2)}_{n_y}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
y^{(N)}_{1} &amp; y^{(N)}_{2} &amp; \cdots &amp; y^{(N)}_{n_y}\\
\end{bmatrix}
\]</span></p>
<details class="question">
<summary>
<strong>Question:</strong> What is the shape of <span class="math inline">\(Y\)</span>?
</summary>
<div class="answer">
<strong>Answer:</strong> The shape of <span class="math inline">\(Y\)</span> is <span class="math inline">\((N \times n_y)\)</span>.
</div>
</details>
<p>Let’s use the <a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST dataset</a> as an example. This dataset comprises a training partition including 60,000 images and a validation partition including 10,000 images. Each image is 28 pixels in height and 28 pixels in width for a total of 784 pixels. Each image contains a single handwritten digit—a number in the range zero through nine). Here is a small sample of these images:</p>
<figure>
<img src="https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png" alt="MNIST Sample. Image from Wikipedia." /><figcaption aria-hidden="true">MNIST Sample. Image from Wikipedia.</figcaption>
</figure>
<details class="question">
<summary>
<strong>Question:</strong> What is the shape of the training partition of the input <span class="math inline">\(X_{train}\)</span>?
</summary>
<div class="answer">
<strong>Answer:</strong> <span class="math inline">\(X_{train}\)</span> is <span class="math inline">\((60000 \times 784\)</span>): <span class="math display">\[X = \begin{bmatrix}
x^{(1)}_{1} &amp; x^{(1)}_{2} &amp; \cdots &amp; x^{(1)}_{784}\\
x^{(2)}_{1} &amp; x^{(2)}_{2} &amp; \cdots &amp; x^{(2)}_{784}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
x^{(60000)}_{1} &amp; x^{(60000)}_{2} &amp; \cdots &amp; x^{(60000)}_{784}\\
\end{bmatrix}
\]</span> The first row includes all 784 pixels of the first training image, and subsequent rows likewise contain pixel data for a single image.
</div>
</details>
<details class="question">
<summary>
<strong>Question:</strong> What is the shape of the training partition of the targets <span class="math inline">\(Y_{train}\)</span>?
</summary>
<div class="answer">
<strong>Answer:</strong> <span class="math inline">\(Y_{train}\)</span> is <span class="math inline">\((60000 \times 10\)</span>): <span class="math display">\[Y = \begin{bmatrix}
x^{(1)}_{1} &amp; x^{(1)}_{2} &amp; \cdots &amp; x^{(1)}_{10}\\
x^{(2)}_{1} &amp; x^{(2)}_{2} &amp; \cdots &amp; x^{(2)}_{10}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
x^{(60000)}_{1} &amp; x^{(60000)}_{2} &amp; \cdots &amp; x^{(60000)}_{10}\\
\end{bmatrix}
\]</span> Each row in this matrix is one-hot encoded, meaning that only one item in each row is “1” and all other items in a row are “0”. Here is an example of a one-hot encoding target for an input image representing the digit “2” <span class="math display">\[y^T = \begin{bmatrix} 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\end{bmatrix}\]</span> To save space we will often just represent a one-hot encoded vector using just the index of the “hot” item. For example, the previous vector can be represented by the integer 2.
</div>
</details>
<details class="question">
<summary>
<strong>Question:</strong> What are the shapes of <span class="math inline">\(X_{valid}\)</span> and <span class="math inline">\(Y_{valid}\)</span>?
</summary>
<div class="answer">
<strong>Answer:</strong> <span class="math inline">\(X_{valid}\)</span> and <span class="math inline">\(Y_{valid}\)</span> are <span class="math inline">\((10000 \times 784)\)</span> and <span class="math inline">\((10000 \times 10)\)</span>, respectively.
</div>
</details>
<p>You might now wonder why we split a dataset into training/validation/evaluation partitions. It is reasonable to think that we would be better off using all 70000 images to train a neural network. However, we need some method for <em>measuring</em> how well a model is performing. We use the validation partition to measure performance.</p>
<p>If we measure performance directly on the training dataset we might trick ourselves into thinking that the neural network will perform very well when it is deployed as part of an application (for example, to convert a an image of someones’s handwritten notes into a text document), when in reality the network might only perform well specifically on the examples found in the training dataset.</p>
<p>Similarly, the evaluation partition is only used to compare performance after hyper-parameter tuning. We’ll discuss this more in sec. <a href="#sec:hyper">12</a>.</p>
<section id="loading-mnist-using-pytorch" class="level2" data-number="3.1">
<h2 data-number="3.1"><span class="header-section-number">3.1</span> Loading MNIST Using PyTorch</h2>
<div class="code-highlight">
<pre><span style="color:#39424e;">   1</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;">!/usr/bin/env python</span>
<span style="color:#39424e;">   2</span> 
<span style="color:#39424e;">   3</span> <span style="color:#ffa759;">from</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">torch</span><span style="color:#f29e74;">.</span><span style="color:#ccc9c2;">utils</span><span style="color:#f29e74;">.</span><span style="color:#ccc9c2;">data</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">import</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">DataLoader</span>
<span style="color:#39424e;">   4</span> 
<span style="color:#39424e;">   5</span> <span style="color:#ffa759;">from</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">torchvision</span><span style="color:#f29e74;">.</span><span style="color:#ccc9c2;">datasets</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">import</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">MNIST</span>
<span style="color:#39424e;">   6</span> <span style="color:#ffa759;">from</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">torchvision</span><span style="color:#f29e74;">.</span><span style="color:#ccc9c2;">transforms</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">import</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">Compose</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">Normalize</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">ToTensor</span>
<span style="color:#39424e;">   7</span> 
<span style="color:#39424e;">   8</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> Location in which to store downloaded data</span>
<span style="color:#39424e;">   9</span> <span style="color:#ccc9c2;">data_dir</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#bae67e;">&quot;</span><span style="color:#bae67e;">../Data</span><span style="color:#bae67e;">&quot;</span>
<span style="color:#39424e;">  10</span> 
<span style="color:#39424e;">  11</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> I used torch.std_mean to find the values given to Normalize</span>
<span style="color:#39424e;">  12</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> We will discuss normalization in section 4</span>
<span style="color:#39424e;">  13</span> <span style="color:#ccc9c2;">mnist_xforms</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">Compose</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">[</span><span style="color:#ffd580;">ToTensor</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">Normalize</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">0</span><span style="color:#ccc9c2;">.</span><span style="color:#ffcc66;">1307</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">0</span><span style="color:#ccc9c2;">.</span><span style="color:#ffcc66;">3081</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">]</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  14</span> 
<span style="color:#39424e;">  15</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> Load data files (training and validation partitions)</span>
<span style="color:#39424e;">  16</span> <span style="color:#ccc9c2;">train_data</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">MNIST</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">root</span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;">data_dir</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">train</span><span style="color:#f29e74;">=</span><span style="color:#ffcc66;">True</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">download</span><span style="color:#f29e74;">=</span><span style="color:#ffcc66;">True</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">transform</span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;">mnist_xforms</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  17</span> <span style="color:#ccc9c2;">valid_data</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">MNIST</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">root</span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;">data_dir</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">train</span><span style="color:#f29e74;">=</span><span style="color:#ffcc66;">False</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">download</span><span style="color:#f29e74;">=</span><span style="color:#ffcc66;">True</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">transform</span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;">mnist_xforms</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  18</span> 
<span style="color:#39424e;">  19</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> Data loaders provide an easy interface for interactive with data</span>
<span style="color:#39424e;">  20</span> <span style="color:#ccc9c2;">train_loader</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">DataLoader</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">train_data</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">batch_size</span><span style="color:#f29e74;">=</span><span style="color:#f28779;">len</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">train_data</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  21</span> <span style="color:#ccc9c2;">valid_loader</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">DataLoader</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">valid_data</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">batch_size</span><span style="color:#f29e74;">=</span><span style="color:#f28779;">len</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">valid_data</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  22</span> 
<span style="color:#39424e;">  23</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> This odd bit of code forces the train loader to give us all inputs and targets</span>
<span style="color:#39424e;">  24</span> <span style="color:#ccc9c2;">X_train</span><span style="color:#ccc9c2;">, </span><span style="color:#ccc9c2;">y_train</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">next</span><span style="color:#ccc9c2;">(</span><span style="color:#f28779;">iter</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">train_loader</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  25</span> <span style="color:#ccc9c2;">X_valid</span><span style="color:#ccc9c2;">, </span><span style="color:#ccc9c2;">y_valid</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">next</span><span style="color:#ccc9c2;">(</span><span style="color:#f28779;">iter</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">valid_loader</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  26</span> 
<span style="color:#39424e;">  27</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> Let&apos;s start by simply printing out some basic information</span>
<span style="color:#39424e;">  28</span> <span style="color:#f28779;">print</span><span style="color:#ccc9c2;">(</span><span style="color:#bae67e;">&quot;</span><span style="color:#bae67e;">Training input shape    :</span><span style="color:#bae67e;">&quot;</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">X_train</span><span style="color:#f29e74;">.</span><span style="color:#ccc9c2;">shape</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  29</span> <span style="color:#f28779;">print</span><span style="color:#ccc9c2;">(</span><span style="color:#bae67e;">&quot;</span><span style="color:#bae67e;">Training target shape   :</span><span style="color:#bae67e;">&quot;</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">y_train</span><span style="color:#f29e74;">.</span><span style="color:#ccc9c2;">shape</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  30</span> <span style="color:#f28779;">print</span><span style="color:#ccc9c2;">(</span><span style="color:#bae67e;">&quot;</span><span style="color:#bae67e;">Validation input shape  :</span><span style="color:#bae67e;">&quot;</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">X_valid</span><span style="color:#f29e74;">.</span><span style="color:#ccc9c2;">shape</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  31</span> <span style="color:#f28779;">print</span><span style="color:#ccc9c2;">(</span><span style="color:#bae67e;">&quot;</span><span style="color:#bae67e;">Validation target shape :</span><span style="color:#bae67e;">&quot;</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">y_valid</span><span style="color:#f29e74;">.</span><span style="color:#ccc9c2;">shape</span><span style="color:#ccc9c2;">)</span>
</pre>
<div class="code-caption">
<a href="https://github.com/SinglePages/NeuralNetworks/blob/main/Code/Python/03-01-LoadMNIST.py">Link to code.</a>
</div>
</div>
<details class="question">
<summary>
<strong>Question:</strong> What do you expect to see as this program’s output?
</summary>
<div class="answer">
<strong>Answer:</strong>
<pre class="code-block">
Training input shape    : torch.Size([60000, 1, 28, 28])
Training target shape   : torch.Size([60000])
Validation input shape  : torch.Size([10000, 1, 28, 28])
Validation target shape : torch.Size([10000])
</pre>
<p>This is slightly different than what we discussed. PyTorch expects us to use this dataset with a convolutional neural network. When we get to sec. <a href="#sec:cnns">9</a> we’ll make more sense of this data format.</p>
</div>
</details>
</section>
</section>
<section id="single-neuron" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Single Neuron</h1>
<p>When our model is a single neuron we can only produce a single output. So, <span class="math inline">\(n_y=1\)</span> for this section. Sticking to our MNSIT digits example from above, we could train a single neuron to distinguish between two different classes (e.g., “1” vs “7”, “0” vs “non-zero”, etc.).</p>
<section id="notation-and-diagram" class="level2" data-number="4.1">
<h2 data-number="4.1"><span class="header-section-number">4.1</span> Notation and Diagram</h2>
<p>Here is a diagram representing a single neuron (as we’ll see later, a neural network often refers to many of these neurons interconnected):</p>
<figure>
<img src="img/NeuronSeparate.svg" alt="A neuron model with separate nodes for linear and activation computations." /><figcaption aria-hidden="true">A neuron model with separate nodes for linear and activation computations.</figcaption>
</figure>
<p>The diagram represents the following equations (note that I removed the parenthesis superscript from the diagram to make it a bit easier to read):</p>
<p><span class="math display">\[\begin{align}
z^{(i)} &amp;= \sum_{k=1}^{n_x} x_k^{(i)} w_k + b\\
a^{(i)} &amp;= g(z^{(i)})
\end{align}\]</span></p>
<p>For these two equations:</p>
<ul>
<li><span class="math inline">\(x_k^{(i)}\)</span> are the input features for the <span class="math inline">\(i^{th}\)</span> example (e.g., <span class="math inline">\(k=76\)</span> and <span class="math inline">\(i=7436\)</span> would denote pixel 76 of 784 for image 7436 of 60000)</li>
<li><span class="math inline">\(w_k\)</span> (weights) and <span class="math inline">\(b\)</span> (bias) are the <strong>learned</strong> parameters</li>
<li><span class="math inline">\(z^{(i)}\)</span> is a weighted sum of the input features plus the additional bias term</li>
<li><span class="math inline">\(a^{(i)}\)</span> is the output of a non-linear activation function <span class="math inline">\(g(\mathord{\cdot})\)</span> applied to <span class="math inline">\(z^{(i)}\)</span></li>
<li><span class="math inline">\(\hat y^{(i)}\)</span> (pronounced <em>“y hat”</em>) is the label we often give to the output (<span class="math inline">\(a^{(i)} = \hat y^{(i)}\)</span>)</li>
</ul>
<details class="question">
<summary>
<strong>Question:</strong> Why do <span class="math inline">\(w_k\)</span> and <span class="math inline">\(b\)</span> not have superscripts?
</summary>
<div class="answer">
<strong>Answer:</strong> The parameters <span class="math inline">\(w_k\)</span> and <span class="math inline">\(b\)</span> do not change as the input <span class="math inline">\(x_k^{(i)}\)</span> changes. These parameters <strong>are</strong> the neuron, and they are used to produce the output <span class="math inline">\(\hat y^{(i)}\)</span> for any given input; we use the same parameter values regardless of input.
</div>
</details>
<p><strong>For this model, we want to find parameters <span class="math inline">\(w_k\)</span> and <span class="math inline">\(b\)</span> such that the neuron outputs <span class="math inline">\(\hat y^{(i)} \approx y\)</span> for any input.</strong> Before we discuss optimization we should take a moment to code up this single neuron model.</p>
<p>Before we continue I should show a more common representation of a neuron model. The image above separates the linear and activation components, but it is more common to show them together in a single node.</p>
<figure>
<img src="img/Neuron.svg" alt="A neuron model." /><figcaption aria-hidden="true">A neuron model.</figcaption>
</figure>
</section>
<section id="neuron-with-python-standard-libraries" class="level2" data-number="4.2">
<h2 data-number="4.2"><span class="header-section-number">4.2</span> Neuron with Python Standard Libraries</h2>
<p>This code does not include any “learning” (i.e., optimization), but it is worth showing just how simple it is to write a single neuron from scratch. Most of the code below is necessary only to create some faked input data.</p>
<div class="code-highlight">
<pre><span style="color:#39424e;">   1</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;">!/usr/bin/env python</span>
<span style="color:#39424e;">   2</span> 
<span style="color:#39424e;">   3</span> <span style="color:#ffa759;">from</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">math</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">import</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">exp</span>
<span style="color:#39424e;">   4</span> <span style="color:#ffa759;">from</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">random</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">import</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">gauss</span>
<span style="color:#39424e;">   5</span> 
<span style="color:#39424e;">   6</span> 
<span style="color:#39424e;">   7</span> <span style="color:#ffa759;">def</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">sigmoid</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">z</span><span style="color:#ccc9c2;">:</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">float</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">-&gt;</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">float</span><span style="color:#ccc9c2;">:</span>
<span style="color:#39424e;">   8</span> <span style="color:#ccc9c2;">    </span><span style="color:#5c6773;">&quot;&quot;&quot;</span><span style="color:#5c6773;">The sigmoid/logistic activation function.</span><span style="color:#5c6773;">&quot;&quot;&quot;</span>
<span style="color:#39424e;">   9</span> <span style="color:#ccc9c2;">    </span><span style="color:#ffa759;">return</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">/</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">+</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">exp</span><span style="color:#ccc9c2;">(</span><span style="color:#f29e74;">-</span><span style="color:#ccc9c2;">z</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  10</span> 
<span style="color:#39424e;">  11</span> 
<span style="color:#39424e;">  12</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> The number of examples in our dataset</span>
<span style="color:#39424e;">  13</span> <span style="color:#ccc9c2;">N</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">100</span>
<span style="color:#39424e;">  14</span> 
<span style="color:#39424e;">  15</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> Randomly generate some input data</span>
<span style="color:#39424e;">  16</span> <span style="color:#ccc9c2;">nx</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">4</span>
<span style="color:#39424e;">  17</span> <span style="color:#ccc9c2;">x1</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">[</span><span style="color:#ffd580;">gauss</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">0</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">for</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">_</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">in</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">range</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">N</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">]</span>
<span style="color:#39424e;">  18</span> <span style="color:#ccc9c2;">x2</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">[</span><span style="color:#ffd580;">gauss</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">0</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">for</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">_</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">in</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">range</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">N</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">]</span>
<span style="color:#39424e;">  19</span> <span style="color:#ccc9c2;">x3</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">[</span><span style="color:#ffd580;">gauss</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">0</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">for</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">_</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">in</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">range</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">N</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">]</span>
<span style="color:#39424e;">  20</span> <span style="color:#ccc9c2;">x4</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">[</span><span style="color:#ffd580;">gauss</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">0</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">for</span><span style="color:#ccc9c2;"> </span><span style="color:#5ccfe6;">_</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">in</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">range</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">N</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">]</span>
<span style="color:#39424e;">  21</span> 
<span style="color:#39424e;">  22</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> Generate random neuron parameters</span>
<span style="color:#39424e;">  23</span> <span style="color:#ccc9c2;">w1</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">gauss</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">0</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  24</span> <span style="color:#ccc9c2;">w2</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">gauss</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">0</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  25</span> <span style="color:#ccc9c2;">w3</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">gauss</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">0</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  26</span> <span style="color:#ccc9c2;">w4</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">gauss</span><span style="color:#ccc9c2;">(</span><span style="color:#ffcc66;">0</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">1</span><span style="color:#ccc9c2;">)</span>
<span style="color:#39424e;">  27</span> <span style="color:#ccc9c2;">b</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">0</span>
<span style="color:#39424e;">  28</span> 
<span style="color:#39424e;">  29</span> <span style="color:#5c6773;">#</span><span style="color:#5c6773;"> Compute neuron output for each of the N examples</span>
<span style="color:#39424e;">  30</span> <span style="color:#ffa759;">for</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x1i</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x2i</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x3i</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x4i</span><span style="color:#ccc9c2;"> </span><span style="color:#ffa759;">in</span><span style="color:#ccc9c2;"> </span><span style="color:#f28779;">zip</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">x1</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x2</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x3</span><span style="color:#ccc9c2;">,</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x4</span><span style="color:#ccc9c2;">)</span><span style="color:#ccc9c2;">:</span>
<span style="color:#39424e;">  31</span> <span style="color:#ccc9c2;">    </span><span style="color:#ccc9c2;">zi</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">w1</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">*</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x1i</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">+</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">w2</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">*</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x2i</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">+</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">w3</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">*</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x3i</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">+</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">w4</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">*</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">x4i</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">+</span><span style="color:#ccc9c2;"> </span><span style="color:#ccc9c2;">b</span>
<span style="color:#39424e;">  32</span> <span style="color:#ccc9c2;">    </span><span style="color:#ccc9c2;">ai</span><span style="color:#ccc9c2;"> </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffd580;">sigmoid</span><span style="color:#ccc9c2;">(</span><span style="color:#ccc9c2;">zi</span><span style="color:#ccc9c2;">)</span>
</pre>
<div class="code-caption">
<a href="https://github.com/SinglePages/NeuralNetworks/blob/main/Code/Python/04-01-SingleNeuronLoop.py">Link to code.</a>
</div>
</div>
</section>
<section id="the-dot-product" class="level2" data-number="4.3">
<h2 data-number="4.3"><span class="header-section-number">4.3</span> The Dot-Product</h2>
<p>We compute <span class="math inline">\(z^{(i)}\)</span> above using a summation, but we can express this same bit of math using the dot-product from linear algebra.</p>
<p><span class="math display">\[
z^{(i)} = \sum_{k=1}^{n_x} x_k^{(i)} w_k + b = \mathbf{x}^{(i)T} \mathbf{w} + b
\]</span></p>
<p>The <span class="math inline">\(\mathbf{x}^{(i)T} \mathbf{w}\)</span> part of the equation computes the dot-product between <span class="math inline">\(\mathbf{x}^{(i)T}\)</span> and <span class="math inline">\(\mathbf{w}\)</span>. We need to transpose <span class="math inline">\(\mathbf{x}^{(i)}\)</span> to make the dimensions work (i.e., we need to multiply a row vector by a column vector).</p>
<p>This not only turns out to be easier to write/type, but it is more efficiently computed by a neural network library. The code listing below uses <a href="https://pytorch.org/">PyTorch</a> to compute <span class="math inline">\(z^{(i)}\)</span> (<code>zi</code>). Libraries like PyTorch and Tensorflow make use of both vectorized CPU instructions and graphics cards (GPUs) to quickly compute the output of matrix multiplications.</p>
<div class="code-highlight">
<pre>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 1  </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 1  </span><span style="color:#0000ee;">│</span><span style="color:#5c6773;">#!/usr/bin/env python</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 2  </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 2  </span><span style="color:#0000ee;">│</span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 3  </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ffa759;background-color:#a61719;">from</span><span style="color:#ccc9c2;background-color:#a61719;"> math </span><span style="color:#ffa759;background-color:#a61719;">import</span><span style="color:#ccc9c2;background-color:#a61719;"> exp</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 4  </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ffa759;background-color:#a61719;">from</span><span style="color:#ccc9c2;background-color:#a61719;"> random </span><span style="color:#ffa759;background-color:#a61719;">import</span><span style="color:#ccc9c2;background-color:#a61719;"> gauss</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 5  </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 6  </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 7  </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ffa759;background-color:#a61719;">def</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffd580;background-color:#a61719;">sigmoid</span><span style="color:#ccc9c2;background-color:#a61719;">(</span><span style="color:#ffcc66;background-color:#a61719;">z</span><span style="color:#ccc9c2;background-color:#a61719;">: </span><span style="color:#5ccfe6;background-color:#a61719;">float</span><span style="color:#ccc9c2;background-color:#a61719;">) -&gt; </span><span style="color:#5ccfe6;background-color:#a61719;">float</span><span style="color:#ccc9c2;background-color:#a61719;">:</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 8  </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#a61719;">    </span><span style="color:#5c6773;background-color:#a61719;">&quot;&quot;&quot;The sigmoid/logistic activation function.&quot;&quot;&quot;</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 9  </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#a61719;">    </span><span style="color:#ffa759;background-color:#a61719;">return</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffcc66;background-color:#a61719;">1</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#f29e74;background-color:#a61719;">/</span><span style="color:#ccc9c2;background-color:#a61719;"> (</span><span style="color:#ffcc66;background-color:#a61719;">1</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#f29e74;background-color:#a61719;">+</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffd580;background-color:#a61719;">exp</span><span style="color:#ccc9c2;background-color:#a61719;">(</span><span style="color:#f29e74;background-color:#a61719;">-</span><span style="color:#ccc9c2;background-color:#a61719;">z))</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 3  </span><span style="color:#0000ee;">│</span><span style="color:#ffa759;background-color:#22a322;">import</span><span style="color:#ccc9c2;background-color:#22a322;"> torch</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 10 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 4  </span><span style="color:#0000ee;">│</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 11 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 5  </span><span style="color:#0000ee;">│</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 12 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 6  </span><span style="color:#0000ee;">│</span><span style="color:#5c6773;"># The number of examples in our dataset</span>

<span style="color:#0000ee;"></span><span style="color:#444444;"> 14 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 8  </span><span style="color:#0000ee;">│</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 15 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 9  </span><span style="color:#0000ee;">│</span><span style="color:#5c6773;"># Randomly generate some input data</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 16 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 10 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;">nx </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">4</span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 17 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#a61719;">x1 </span><span style="color:#f29e74;background-color:#a61719;">=</span><span style="color:#ccc9c2;background-color:#a61719;"> [</span><span style="color:#ffd580;background-color:#a61719;">gauss</span><span style="color:#ccc9c2;background-color:#a61719;">(</span><span style="color:#ffcc66;background-color:#a61719;">0</span><span style="color:#ccc9c2;background-color:#a61719;">, </span><span style="color:#ffcc66;background-color:#a61719;">1</span><span style="color:#ccc9c2;background-color:#a61719;">) </span><span style="color:#ffa759;background-color:#a61719;">for</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#5ccfe6;background-color:#a61719;">_</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffa759;background-color:#a61719;">in</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#f28779;background-color:#a61719;">range</span><span style="color:#ccc9c2;background-color:#a61719;">(N)]</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 18 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#a61719;">x2 </span><span style="color:#f29e74;background-color:#a61719;">=</span><span style="color:#ccc9c2;background-color:#a61719;"> [</span><span style="color:#ffd580;background-color:#a61719;">gauss</span><span style="color:#ccc9c2;background-color:#a61719;">(</span><span style="color:#ffcc66;background-color:#a61719;">0</span><span style="color:#ccc9c2;background-color:#a61719;">, </span><span style="color:#ffcc66;background-color:#a61719;">1</span><span style="color:#ccc9c2;background-color:#a61719;">) </span><span style="color:#ffa759;background-color:#a61719;">for</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#5ccfe6;background-color:#a61719;">_</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffa759;background-color:#a61719;">in</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#f28779;background-color:#a61719;">range</span><span style="color:#ccc9c2;background-color:#a61719;">(N)]</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 19 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#a61719;">x3 </span><span style="color:#f29e74;background-color:#a61719;">=</span><span style="color:#ccc9c2;background-color:#a61719;"> [</span><span style="color:#ffd580;background-color:#a61719;">gauss</span><span style="color:#ccc9c2;background-color:#a61719;">(</span><span style="color:#ffcc66;background-color:#a61719;">0</span><span style="color:#ccc9c2;background-color:#a61719;">, </span><span style="color:#ffcc66;background-color:#a61719;">1</span><span style="color:#ccc9c2;background-color:#a61719;">) </span><span style="color:#ffa759;background-color:#a61719;">for</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#5ccfe6;background-color:#a61719;">_</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffa759;background-color:#a61719;">in</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#f28779;background-color:#a61719;">range</span><span style="color:#ccc9c2;background-color:#a61719;">(N)]</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 20 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#a61719;">x4 </span><span style="color:#f29e74;background-color:#a61719;">=</span><span style="color:#ccc9c2;background-color:#a61719;"> [</span><span style="color:#ffd580;background-color:#a61719;">gauss</span><span style="color:#ccc9c2;background-color:#a61719;">(</span><span style="color:#ffcc66;background-color:#a61719;">0</span><span style="color:#ccc9c2;background-color:#a61719;">, </span><span style="color:#ffcc66;background-color:#a61719;">1</span><span style="color:#ccc9c2;background-color:#a61719;">) </span><span style="color:#ffa759;background-color:#a61719;">for</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#5ccfe6;background-color:#a61719;">_</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffa759;background-color:#a61719;">in</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#f28779;background-color:#a61719;">range</span><span style="color:#ccc9c2;background-color:#a61719;">(N)]</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 11 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#22a322;">X </span><span style="color:#f29e74;background-color:#22a322;">=</span><span style="color:#ccc9c2;background-color:#22a322;"> torch</span><span style="color:#f29e74;background-color:#22a322;">.</span><span style="color:#ffd580;background-color:#22a322;">randn</span><span style="color:#ccc9c2;background-color:#22a322;">(N, nx)</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 21 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 12 </span><span style="color:#0000ee;">│</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 22 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 13 </span><span style="color:#0000ee;">│</span><span style="color:#5c6773;"># Generate random neuron parameters</span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 23 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#a61719;">w1 </span><span style="color:#f29e74;background-color:#a61719;">=</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffd580;background-color:#a61719;">gauss</span><span style="color:#ccc9c2;background-color:#a61719;">(</span><span style="color:#ffcc66;background-color:#a61719;">0</span><span style="color:#ccc9c2;background-color:#a61719;">, </span><span style="color:#ffcc66;background-color:#a61719;">1</span><span style="color:#ccc9c2;background-color:#a61719;">)</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 24 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#a61719;">w2 </span><span style="color:#f29e74;background-color:#a61719;">=</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffd580;background-color:#a61719;">gauss</span><span style="color:#ccc9c2;background-color:#a61719;">(</span><span style="color:#ffcc66;background-color:#a61719;">0</span><span style="color:#ccc9c2;background-color:#a61719;">, </span><span style="color:#ffcc66;background-color:#a61719;">1</span><span style="color:#ccc9c2;background-color:#a61719;">)</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 25 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#a61719;">w3 </span><span style="color:#f29e74;background-color:#a61719;">=</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffd580;background-color:#a61719;">gauss</span><span style="color:#ccc9c2;background-color:#a61719;">(</span><span style="color:#ffcc66;background-color:#a61719;">0</span><span style="color:#ccc9c2;background-color:#a61719;">, </span><span style="color:#ffcc66;background-color:#a61719;">1</span><span style="color:#ccc9c2;background-color:#a61719;">)</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 26 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#a61719;">w4 </span><span style="color:#f29e74;background-color:#a61719;">=</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffd580;background-color:#a61719;">gauss</span><span style="color:#ccc9c2;background-color:#a61719;">(</span><span style="color:#ffcc66;background-color:#a61719;">0</span><span style="color:#ccc9c2;background-color:#a61719;">, </span><span style="color:#ffcc66;background-color:#a61719;">1</span><span style="color:#ccc9c2;background-color:#a61719;">)</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 14 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#22a322;">w </span><span style="color:#f29e74;background-color:#22a322;">=</span><span style="color:#ccc9c2;background-color:#22a322;"> torch</span><span style="color:#f29e74;background-color:#22a322;">.</span><span style="color:#ffd580;background-color:#22a322;">randn</span><span style="color:#ccc9c2;background-color:#22a322;">(nx)</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 27 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 15 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;">b </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">0</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 28 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 16 </span><span style="color:#0000ee;">│</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 29 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 17 </span><span style="color:#0000ee;">│</span><span style="color:#5c6773;"># Compute neuron output for each of the N examples</span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 30 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ffa759;background-color:#a61719;">for</span><span style="color:#ccc9c2;background-color:#a61719;"> x1i, x2i, x3i, x4i </span><span style="color:#ffa759;background-color:#a61719;">in</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#f28779;background-color:#a61719;">zip</span><span style="color:#ccc9c2;background-color:#a61719;">(x1, x2, x3, x4):</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 31 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#a61719;">    zi </span><span style="color:#f29e74;background-color:#a61719;">=</span><span style="color:#ccc9c2;background-color:#a61719;"> w1 </span><span style="color:#f29e74;background-color:#a61719;">*</span><span style="color:#ccc9c2;background-color:#a61719;"> x1i </span><span style="color:#f29e74;background-color:#a61719;">+</span><span style="color:#ccc9c2;background-color:#a61719;"> w2 </span><span style="color:#f29e74;background-color:#a61719;">*</span><span style="color:#ccc9c2;background-color:#a61719;"> x2i </span><span style="color:#f29e74;background-color:#a61719;">+</span><span style="color:#ccc9c2;background-color:#a61719;"> w3 </span><span style="color:#f29e74;background-color:#a61719;">*</span><span style="color:#ccc9c2;background-color:#a61719;"> x3i </span><span style="color:#f29e74;background-color:#a61719;">+</span><span style="color:#ccc9c2;background-color:#a61719;"> w4 </span><span style="color:#f29e74;background-color:#a61719;">*</span><span style="color:#ccc9c2;background-color:#a61719;"> x4i </span><span style="color:#f29e74;background-color:#a61719;">+</span><span style="color:#ccc9c2;background-color:#a61719;"> b</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 32 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#a61719;">    ai </span><span style="color:#f29e74;background-color:#a61719;">=</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#ffd580;background-color:#a61719;">sigmoid</span><span style="color:#ccc9c2;background-color:#a61719;">(zi)</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 18 </span><span style="color:#0000ee;">│</span><span style="color:#ffa759;background-color:#22a322;">for</span><span style="color:#ccc9c2;background-color:#22a322;"> xi </span><span style="color:#ffa759;background-color:#22a322;">in</span><span style="color:#ccc9c2;background-color:#22a322;"> X:</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 19 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#22a322;">    zi </span><span style="color:#f29e74;background-color:#22a322;">=</span><span style="color:#ccc9c2;background-color:#22a322;"> xi </span><span style="color:#f29e74;background-color:#22a322;">&#64;</span><span style="color:#ccc9c2;background-color:#22a322;"> w </span><span style="color:#f29e74;background-color:#22a322;">+</span><span style="color:#ccc9c2;background-color:#22a322;"> b</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 20 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;background-color:#22a322;">    ai </span><span style="color:#f29e74;background-color:#22a322;">=</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="font-weight:bold;color:#7f7f7f;background-color:#006000;">torch</span><span style="font-weight:bold;color:#f29e74;background-color:#006000;">.</span><span style="color:#ffd580;background-color:#22a322;">sigmoid</span><span style="color:#ccc9c2;background-color:#22a322;">(zi)</span><span style="background-color:#22a322;"></span>
</pre>
<div class="code-caption">
<a href="https://github.com/SinglePages/NeuralNetworks/blob/main/Code/Python/04-02-SingleNeuronDot.py">Link to code.</a>
</div>
</div>
<p>The code snippet above shows a <a href="https://en.wikipedia.org/wiki/Diff">diff</a> between the previous code snippet and an updated one using the dot product. You will see many diffs throughout this document. The key points are that: (1) red indicates text or entire lines that have been removed and (2) green indicates updated or newly added lines.</p>
<p>We do not need to transpose <code>xi</code> in code because when we iteration through <code>X</code> we get row vectors. As it happens, we can improve efficiency even further.</p>
</section>
<section id="vectorizing-inputs" class="level2" data-number="4.4">
<h2 data-number="4.4"><span class="header-section-number">4.4</span> Vectorizing Inputs</h2>
<p>In addition to using a dot-product in place of a summation, we can use a matrix multiplication in place of looping over all examples in the dataset. In the two equations below we perform a matrix multiplication that computes the output of the network for all examples at once. A neural network library can turn this into highly efficient CPU or GPU operations.</p>
<p><span class="math display">\[\begin{align}
\mathbf{z} &amp;= X \mathbf{w} + b \\
\mathbf{a} &amp;= g(\mathbf{z})
\end{align}\]</span></p>
<div class="code-highlight">
<pre>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 15 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 15 </span><span style="color:#0000ee;">│</span><span style="color:#ccc9c2;">b </span><span style="color:#f29e74;">=</span><span style="color:#ccc9c2;"> </span><span style="color:#ffcc66;">0</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 16 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 16 </span><span style="color:#0000ee;">│</span>
<span style="color:#0000ee;"></span><span style="color:#444444;"> 17 </span><span style="color:#0000ee;">│</span><span style="color:#444444;"> 17 </span><span style="color:#0000ee;">│</span><span style="color:#5c6773;"># Compute neuron output for each of the N examples</span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 18 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="color:#ffa759;background-color:#a61719;">for</span><span style="color:#ccc9c2;background-color:#a61719;"> xi </span><span style="color:#ffa759;background-color:#a61719;">in</span><span style="color:#ccc9c2;background-color:#a61719;"> X:</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 19 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="font-weight:bold;color:#ccc9c2;background-color:#901011;">    zi </span><span style="color:#f29e74;background-color:#a61719;">=</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="font-weight:bold;color:#7f7f7f;background-color:#901011;">xi</span><span style="color:#ccc9c2;background-color:#a61719;"> </span><span style="color:#f29e74;background-color:#a61719;">&#64;</span><span style="color:#ccc9c2;background-color:#a61719;"> w </span><span style="color:#f29e74;background-color:#a61719;">+</span><span style="color:#ccc9c2;background-color:#a61719;"> b</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;"> 20 </span><span style="color:#0000ee;">│</span><span style="color:#008700;">    </span><span style="color:#0000ee;">│</span><span style="font-weight:bold;color:#ccc9c2;background-color:#901011;">    ai </span><span style="color:#f29e74;background-color:#a61719;">=</span><span style="color:#ccc9c2;background-color:#a61719;"> torch</span><span style="color:#f29e74;background-color:#a61719;">.</span><span style="color:#ffd580;background-color:#a61719;">sigmoid</span><span style="color:#ccc9c2;background-color:#a61719;">(</span><span style="font-weight:bold;color:#7f7f7f;background-color:#901011;">zi</span><span style="color:#ccc9c2;background-color:#a61719;">)</span><span style="background-color:#a61719;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 18 </span><span style="color:#0000ee;">│</span><span style="font-weight:bold;color:#ccc9c2;background-color:#006000;">z </span><span style="color:#f29e74;background-color:#22a322;">=</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="font-weight:bold;color:#7f7f7f;background-color:#006000;">X</span><span style="color:#ccc9c2;background-color:#22a322;"> </span><span style="color:#f29e74;background-color:#22a322;">&#64;</span><span style="color:#ccc9c2;background-color:#22a322;"> w </span><span style="color:#f29e74;background-color:#22a322;">+</span><span style="color:#ccc9c2;background-color:#22a322;"> b</span><span style="background-color:#22a322;"></span>
<span style="color:#0000ee;"></span><span style="color:#870000;">    </span><span style="color:#0000ee;">│</span><span style="color:#008700;"> 19 </span><span style="color:#0000ee;">│</span><span style="font-weight:bold;color:#ccc9c2;background-color:#006000;">yhat </span><span style="color:#f29e74;background-color:#22a322;">=</span><span style="color:#ccc9c2;background-color:#22a322;"> torch</span><span style="color:#f29e74;background-color:#22a322;">.</span><span style="color:#ffd580;background-color:#22a322;">sigmoid</span><span style="color:#ccc9c2;background-color:#22a322;">(</span><span style="font-weight:bold;color:#7f7f7f;background-color:#006000;">z</span><span style="color:#ccc9c2;background-color:#22a322;">)</span><span style="background-color:#22a322;"></span>
</pre>
<div class="code-caption">
<a href="https://github.com/SinglePages/NeuralNetworks/blob/main/Code/Python/04-03-SingleNeuronVectorized.py">Link to code.</a>
</div>
</div>
<details class="question">
<summary>
<strong>Question:</strong> What are the dimensions of <span class="math inline">\(\mathbf{z}\)</span> and <span class="math inline">\(\mathbf{a}\)</span> (aka, <span class="math inline">\(\mathbf{\hat y}\)</span>)?
</summary>
<div class="answer">
<p><strong>Answer:</strong> We are computing a single output value for each input, so, the shape of these vectors are <span class="math inline">\((N \times 1)\)</span>. PyTorch will treat these as arrays with <span class="math inline">\(N\)</span> elements instead of as column vectors. <span class="math display">\[\begin{align}
\mathbf{z} &amp;= \begin{bmatrix}
\mathbf{x}^{(1)T} \mathbf{w} + b \\
\mathbf{x}^{(2)T} \mathbf{w} + b \\
\vdots \\
\mathbf{x}^{(N)T} \mathbf{w} + b \\
\end{bmatrix}
 \\
\mathbf{a} &amp;= \begin{bmatrix}
g(z^{(1)}) \\
g(z^{(2)}) \\
\vdots \\
g(z^{(N)}) \\
\end{bmatrix}

\end{align}\]</span></p>
</div>
</details>
<p>In the code snippet above, a matrix multiplication is indicated in PyTorch using the <code>@</code> symbol (a <code>*</code> is used for element-wise multiplications). A key to understanding matrix math is to examine the shapes of all matrices involved. Above, <span class="math inline">\(X\)</span> has a shape of <span class="math inline">\((N \times n_x)\)</span>, <span class="math inline">\(\mathbf{w}\)</span> has a shape of <span class="math inline">\((n_x \times 1)\)</span>, and <span class="math inline">\(b\)</span> is a scalar.</p>
<p>Inner dimensions (the last dimension of the left matrix and the first dimension of the right matrix) must be the same for any valid matrix multiplication. The scalar, <span class="math inline">\(b\)</span>, is added element-wise to every element in the final matrix due to <a href="https://pytorch.org/docs/stable/notes/broadcasting.html">broadcasting</a> (this is a common library feature, not necessarily standard linear algebra).</p>
<p>So far, we have random parameters and we ignore the output. But what if we want to train the neuron so that the output mimics a real function or process? The next subsection tackles this very problem.</p>
</section>
</section>
<section id="multi-layer-networks" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Multi-Layer Networks</h1>
<figure>
<img src="img/2LayerNetwork.svg" alt="A two-layer neural network." /><figcaption aria-hidden="true">A two-layer neural network.</figcaption>
</figure>
<ul>
<li>Layer 0 is the input (formerly X)</li>
<li>Bracket superscript gives the layer</li>
<li>Parentheses superscript gives the example index (removed for readability)</li>
<li>Subscript gives neuron index, previous layer neuron index</li>
</ul>
<p>Single neuron uses the same equations as above</p>
<p>Grouping neurons</p>
<p><span class="math display">\[\begin{align}
W^{[l]} &amp;= \begin{bmatrix}
w_{1,1}^{[l]} &amp; w_{1,2}^{[l]} &amp; \cdots &amp; w_{1,n_{l-1}}^{[l]}\\
w_{2,1}^{[l]} &amp; w_{2,2}^{[l]} &amp; \cdots &amp; w_{2,n_{l-1}}^{[l]}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
w_{n_l,1}^{[l]} &amp; w_{n_l,2}^{[l]} &amp; \cdots &amp; w_{n_l,n_{l-1}}^{[l]}\\
\end{bmatrix}
 \\
\mathbf{b}^{[l]} &amp;= \begin{bmatrix}
b_{1}^{[l]} \\
b_{2}^{[l]} \\
\vdots \\
b_{n_l}^{[l]} \\
\end{bmatrix}
\end{align}\]</span></p>
<p><span class="math display">\[Z^{[l]} = A^{[l-1]} W^{[l]T}\]</span></p>
<details class="question">
<summary>
<strong>Question:</strong> What is the shape of <span class="math inline">\(Z^{[l]}\)</span>?
</summary>
<div class="answer">
<strong>Answer:</strong> <span class="math inline">\(Z^{[l]}\)</span> is <span class="math inline">\((N \times n_l)\)</span>. <span class="math display">\[Z^{[l]} = \begin{bmatrix}
z_{1}^{[l](1)} &amp; z_{2}^{[l](1)} &amp; \cdots &amp; z_{n_l}^{[l](1)}\\
z_{1}^{[l](2)} &amp; z_{2}^{[l](2)} &amp; \cdots &amp; z_{n_l}^{[l](2)}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
z_{1}^{[l](N)} &amp; z_{2}^{[l](N)} &amp; \cdots &amp; z_{n_l}^{[l](N)}\\
\end{bmatrix}
\]</span>
</div>
</details>
<p><span class="math display">\[A^{[l]} = g(Z^{[l]})\]</span></p>
<details class="question">
<summary>
<strong>Question:</strong> What is the shape of <span class="math inline">\(A^{[l]}\)</span>?
</summary>
<div class="answer">
<p><strong>Answer:</strong> <span class="math inline">\(A^{[l]}\)</span> is <span class="math inline">\((N \times n_l)\)</span>. <span class="math display">\[\begin{align}
A^{[l]} &amp;= \begin{bmatrix}
a_{1}^{[l](1)} &amp; a_{2}^{[l](1)} &amp; \cdots &amp; a_{n_l}^{[l](1)}\\
a_{1}^{[l](2)} &amp; a_{2}^{[l](2)} &amp; \cdots &amp; a_{n_l}^{[l](2)}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{1}^{[l](N)} &amp; a_{2}^{[l](N)} &amp; \cdots &amp; a_{n_l}^{[l](N)}\\
\end{bmatrix}
 \\
\\
&amp;= \begin{bmatrix}
g(z_{1}^{[l](1)}) &amp; g(z_{2}^{[l](1)}) &amp; \cdots &amp; g(z_{n_l}^{[l](1)})\\
g(z_{1}^{[l](2)}) &amp; g(z_{2}^{[l](2)}) &amp; \cdots &amp; g(z_{n_l}^{[l](2)})\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
g(z_{1}^{[l](N)}) &amp; g(z_{2}^{[l](N)}) &amp; \cdots &amp; g(z_{n_l}^{[l](N)})\\
\end{bmatrix}
 \\
\\
&amp;= \begin{bmatrix}
g(\mathbf{a}^{[l-1](1)} \mathbf{w}_{1}^{[l]T} + b_{1}^{[l]}) &amp; g(\mathbf{a}^{[l-1](1)} \mathbf{w}_{2}^{[l]T} + b_{2}^{[l]}) &amp; \cdots &amp; g(\mathbf{a}^{[l-1](1)} \mathbf{w}_{n_l}^{[l]T} + b_{n_l}^{[l]})\\
g(\mathbf{a}^{[l-1](2)} \mathbf{w}_{1}^{[l]T} + b_{1}^{[l]}) &amp; g(\mathbf{a}^{[l-1](2)} \mathbf{w}_{2}^{[l]T} + b_{2}^{[l]}) &amp; \cdots &amp; g(\mathbf{a}^{[l-1](2)} \mathbf{w}_{n_l}^{[l]T} + b_{n_l}^{[l]})\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
g(\mathbf{a}^{[l-1](N)} \mathbf{w}_{1}^{[l]T} + b_{1}^{[l]}) &amp; g(\mathbf{a}^{[l-1](N)} \mathbf{w}_{2}^{[l]T} + b_{2}^{[l]}) &amp; \cdots &amp; g(\mathbf{a}^{[l-1](N)} \mathbf{w}_{n_l}^{[l]T} + b_{n_l}^{[l]})\\
\end{bmatrix}
\end{align}\]</span></p>
<p>You should also think about the shapes of <span class="math inline">\(\mathbf{a}^{[l-1](i)}\)</span> and <span class="math inline">\(\mathbf{w}_{j}^{[l]}\)</span>.</p>
</div>
</details>
</section>
<section id="gradient-descent" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Gradient Descent</h1>
<p><em>Being revised</em> </p>
</section>
<section id="optimization-techniques" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Optimization Techniques</h1>
<p><em>Being revised</em></p>
</section>
<section id="overfitting-and-generalization" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Overfitting and Generalization</h1>
<p><em>Being revised</em></p>
</section>
<section id="sec:cnns" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Convolutional Neural Networks</h1>
<p><em>Being revised</em></p>
</section>
<section id="recurrent-neural-networks" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Recurrent Neural Networks</h1>
<p><em>Being revised</em></p>
</section>
<section id="transformers" class="level1" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> Transformers</h1>
<p><em>Being revised</em></p>
</section>
<section id="sec:hyper" class="level1" data-number="12">
<h1 data-number="12"><span class="header-section-number">12</span> Advanced Topics</h1>
<p><em>Being revised</em></p>
</section>
<section id="sec:terms" class="level1 unnumbered">
<h1 class="unnumbered">Terminology</h1>
</section>
</body>
</html>
